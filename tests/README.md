# Cross-Language Test Data

This directory contains reference test data shared across all language implementations.
Each language loads these JSON files to verify correctness and cross-language consistency.

## Directory Structure

```
tests/
│
│   # One-Sample Estimators
├── center/              # Center estimator tests
├── center-bounds/       # CenterBounds estimator tests
├── spread/              # Spread estimator tests
├── spread-bounds/       # SpreadBounds estimator tests
├── rel-spread/          # RelSpread estimator tests
│
│   # Two-Sample Estimators
├── shift/               # Shift estimator tests
├── shift-bounds/        # ShiftBounds estimator tests
├── ratio/               # Ratio estimator tests
├── ratio-bounds/        # RatioBounds estimator tests
├── disparity/           # Disparity estimator tests
├── disparity-bounds/    # DisparityBounds estimator tests
│
│   # Randomization
├── rng/                 # Random number generator tests
├── sample/              # Sample without replacement tests
├── shuffle/             # Shuffle tests
├── resample/            # Resample with replacement (bootstrap) tests
│
│   # Auxiliary
├── avg-spread/          # AvgSpread estimator tests
├── avg-spread-bounds/   # AvgSpreadBounds estimator tests
├── pairwise-margin/     # PairwiseMargin function tests
├── signed-rank-margin/  # SignedRankMargin function tests
│
│   # Other
└── distributions/       # Distribution sampling tests
```

## Test File Format

Each test file is a JSON object with `input` and `output` fields:

```json
{
  "input": { ... },
  "output": ...
}
```

### One-sample estimators (center, spread, rel-spread)

```json
{
  "input": { "x": [1, 2, 3, 4, 5] },
  "output": 3.0
}
```

### Two-sample estimators (shift, ratio, disparity)

```json
{
  "input": { "x": [1, 2, 3], "y": [4, 5, 6] },
  "output": -3.0
}
```

### PairwiseMargin (two-sample)

```json
{
  "input": { "n": 10, "m": 10, "misrate": 0.05 },
  "output": 42
}
```

### SignedRankMargin (one-sample)

```json
{
  "input": { "n": 10, "misrate": 0.05 },
  "output": 6
}
```

### Bounds estimators (shift-bounds, ratio-bounds, center-bounds)

```json
{
  "input": { "x": [1, 2, 3, 4, 5], "misrate": 0.1 },
  "output": { "lower": 1.5, "upper": 4.5 }
}
```

### SpreadBounds / AvgSpreadBounds / DisparityBounds

```json
{
  "input": { "x": [1, 2, 3, 4, 5], "misrate": 0.5, "seed": "spread-bounds-tests" },
  "output": { "lower": 1.0, "upper": 3.0 }
}
```

These use a `seed` field for deterministic randomization. `AvgSpreadBounds` and `DisparityBounds`
take two samples (`x` and `y`).

### sample / resample

Both use the same format. `sample` draws without replacement; `resample` draws with replacement (bootstrap).

```json
{
  "input": { "seed": 1729, "x": [0, 1, 2, 3, 4], "k": 3 },
  "output": [3.0, 1.0, 4.0]
}
```

### Error test cases

Error test cases verify domain validation. They use `expected_error` instead of `output`:

```json
{
  "input": { "n": 1, "misrate": 0.5 },
  "expected_error": {
    "id": "domain"
  }
}
```

The `id` field identifies the assumption violation type (e.g., "domain", "validity", "positivity", "sparity").
Test data matches on `id` only. The language-level violation schema also includes a `subject` field
(e.g., "x", "y", "misrate"), but test assertions only verify the `id`.

## Test Case Naming

Test cases follow a consistent naming taxonomy:

| Prefix | Purpose |
|--------|---------|
| `demo-*` | Basic demonstration cases from documentation |
| `edge-*` | Edge cases and boundary conditions |
| `boundary-*` | Boundary value tests |
| `exact-*` | Exact algorithm tests (vs approximation) |
| `property-*` | Algebraic property verification |
| `unsorted-*` | Stable behavior on non-sorted inputs |
| `natural-*` | Natural number sequences (1, 2, 3, ...) |
| `additive-*` | Additive distribution samples |
| `uniform-*` | Uniform distribution samples |
| `asymmetric-*` | Asymmetric distribution tests |
| `symmetric-*` | Symmetric distribution tests |
| `medium-*` | Medium-size sample tests |
| `misrate-*` | Misrate parameter variation tests |
| `conservatism-*` | Conservatism tests (discreteness effects across sample sizes) |

### Misrate notation

Misrate values use compact notation: `misrate-<mantissa>e-<exponent>` represents `mantissa × 10^-exponent`:
- `misrate-1e-1` = 0.1 (10%)
- `misrate-5e-2` = 0.05 (5%)
- `misrate-1e-2` = 0.01 (1%)

## Tolerance Values

Tests use these standard tolerances for floating-point comparison:

| Tolerance | Value | Usage |
|-----------|-------|-------|
| Exact | 1e-15 | RNG reproducibility tests |
| Strict | 1e-10 | Exact algorithms (margin functions) |
| Standard | 1e-9 | Most estimators |
| Relaxed | 1e-6 | Bootstrap/approximate methods (reserved for future use) |

## Adding New Tests

Test data is generated by two separate generators:

1. **Estimator tests** are generated by the C# test generator:
   ```bash
   mise run cs:gen
   ```

2. **RNG and randomization tests** (rng/, shuffle/, sample/, resample/) are generated by the Rust generator:
   ```bash
   mise run rs:gen:rng-tests
   ```

Run all language CIs to verify:
```bash
mise run ci
```

## Language Coverage

Not all test suites apply to every language. Some suites test type-specific behavior
that only exists in certain languages:

| Suite | C# | Go | Kotlin | Python | R | Rust | TypeScript |
|-------|----|----|--------|--------|---|------|------------|
| `uniform-seed-*` (f64) | x | x | x | x | x | x | x |
| `uniform-f32-*` | x | x | x | - | - | x | - |
| `uniform-int-*` (i64) | x | x | x | x | x | x | x |
| `uniform-i32-*` | x | x | x | - | - | x | - |
| `uniform-bool-*` | x | x | x | x | x | x | x |
| `uniform-string-*` | x | x | x | x | x | x | x |
| `uniform-range-*` | x | x | x | x | x | x | x |
| `shuffle/*` | x | x | x | x | x | x | x |
| `sample/*` | x | x | x | x | x | x | x |
| `resample/*` | x | x | x | x | x | x | x |

**Notes:**
- `uniform-f32-*`: Tests 32-bit float generation. Python, R, and TypeScript lack native f32.
- `uniform-i32-*`: Tests 32-bit integer generation. Python, R, and TypeScript lack native i32.

## Test Generation

Estimator tests are generated from `cs/Pragmastat.TestGenerator/`. Each `*TestCases.cs` file
defines inputs, and the framework computes expected outputs using the C# implementation
as the reference.

RNG and randomization tests are generated from `rs/pragmastat/examples/gen_rng_tests.rs`.
The Rust implementation serves as the reference for cross-language RNG reproducibility.

See `manual/tests/` for documentation of each test suite's purpose and coverage.
